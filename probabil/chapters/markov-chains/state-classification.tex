%<*probabil-2025-11-19-stany-definicje1>
\begin{definition}
	Stan \(i\) jest \textbf{pochłaniający} jeśli \(p_{ii} = 1\).
\end{definition}

\begin{definition}
	Stan \(j\) jest \textbf{osiągalny} ze stanu \(i\) jeśli istnieje \(n \geq 0\) takie, że
	\(p_{ij}(n) > 0\).
\end{definition}

\begin{definition}
	Stany \(i\) oraz \(j\) są \textbf{wzajemnie skomunikowane} jeśli \(i\) jest osiągalne z \(j\) oraz
	\(j\) jest osiągalne z \(i\). Zapisujemy \( i \leftrightarrow j \).
\end{definition}

\begin{lemma}
	Relacja skomunikowania jest relacją równoważności.
\end{lemma}
\begin{proof} Rozważamy trzy warunki bycia relacją równoważności
	\begin{enumerate}
		\item \( i \leftrightarrow i \) \\
		      Możemy dojść z \( i \) do \( i \) w 0 krokach -- \(p_{ij}(0) = 1\)

		\item \( i \leftrightarrow j \implies j \leftrightarrow i \) \\
		      Koniunkcja jest przemienna, możemy zatem zamienić kolejność warunków w definicji.

		\item \( i \leftrightarrow j \land j \leftrightarrow k \implies i \leftrightarrow k \) \\
		      Skoro \( i \leftrightarrow j \) to mamy \( n \) dla którego \(\p_{ij}(n) > 0\).

		      Podobnie mamy \( m \) dla którego \( \p_{jk}(m) > 0 \).

		      W takim razie \( p_{ik}(n+m) \geq p_{ij}(n) \cdot \p_{jk}(m) > 0 \)
		      zatem \( k \) jest osiągalne z \( i \).

		      Analogicznie pokazujemy, że \( i \) jest osiągalne z \( k \), czyli stany te są skomunikowane.

	\end{enumerate}
\end{proof}

Dodatkowo w grafie skierowanym klasy równoważności relacji \( \leftrightarrow \) tworzą silnie spójne składowe.

\begin{definition}
	Stan \( i \) jest \textbf{nieistotny} jeśli \( \exists_j : i \rightarrow j \land j \nrightarrow i \)
\end{definition}
%</probabil-2025-11-19-stany-definicje1>

%<*probabil-2025-11-19-lancuchy-nieprzywiedlne>
\begin{definition}
	Łańcuch jest \textbf{nieprzywiedlny (nieredukowalny)} jeśli wszystkie stany są parami skomunikowane. Wtedy jego graf skierowany jest silnie spójny.
\end{definition}

\begin{definition}
	Stan \(i\) jest \textbf{okresowy} jeśli \( o(i) > 1 \), czyli jego okres jest większy od 1.
	Łańcuch jest okresowy jeśli posiada co najmniej jeden stan okresowy.
	Stan lub łańcuch, które nie są okresowe nazywamy nieokresowymi.
\end{definition}

\begin{lemma}
	W nieprzywiedlnym łańcuchu Markowa wszystkie stany mają ten sam okres.
\end{lemma}
\begin{proof}
	Niech \( i, j \in S \) - dwa stany łańcucha.

	Z nieprzywiedlności mamy:
	\[
		\exists_m p_{ij}(m) > 0
	\]
	\[
		\exists_l p_{ji}(l) > 0
	\]
	Niech \( n \in \mathcal{T}(j) \)
	\[
		p_{ii}(m + n + l) \geq p_{ij}(m) \cdot p_{jj}(n) \cdot p_{ji}(l) > 0
	\]
	\[
		p_{ii}(m + l) \geq p_{ij}(m) \cdot p_{ji}(l) > 0
	\]
	To znaczy chcemy dojść z \( i \) do \( i \) w \(m + n + l\) krokach, więc możemy iść z \( i \) do \( j \), z \( j \) do \( j \) i z \( j \) do \( i \). W drugim przypadku pomijamy \( n \) kroków z \( j \) do \( j \).
	\[
		m+n+l \in \mathcal{T}(i) \implies o(i)|m+n+l
	\]
	\[
		m+l \in \mathcal{T}(i) \implies o(i)|m+l
	\]
	\[
		\implies o(i)|n \implies o(i) \leq o(j)
	\]
	Analogicznie dowodzimy w drugą stronę, otrzymując równość.
\end{proof}

\begin{lemma}
	Jeśli \( \pars{ X_t \mid t \in \natural } \) jest nieokresowym (okres jest równy 1) i nieprzywiedlnym łańcuchem Markowa, to:
	\[
		\forall_{i, j \in S} \exists_{n_0} \forall_{n \geq n_0} P_{ij}(n) > 0
	\]
\end{lemma}
\begin{proof}
	Lemat Schura:
	\[
		\forall_{x \subset \natural^+, \gcd(x) = 1} \exists_{m_0} \forall_{m \geq m_0} 
		\exists_{r \geq 1, x_1, \ldots, x_r \in x, l_1, \ldots, l_r \ in \natural} : \sum_{i \in [r]}l_ix_i = m
	\]
	Niech \( i, j \in S \)\\
	Z lematu Schura mamy:
	\[
		\exists_{m_0} \forall_{m \geq m_0} \exists_{r \geq 1, m_1, \ldots, m_r \in \mathcal{T}(j), l_1, \ldots, l_r \in \natural} : \sum_{i \in [r]} l_im_i = m
	\]
	\[
		P_{jj}(m) \geq \prod_{i \in [r]}P_{jj}(l_im_i) \geq \prod_{i \in [r]} P_{jj}(m_i)^{l_i} > 0
	\]
	Z kolei z nieprzywiedlności mamy:
	\[
		i \rightarrow j \implies \exists_{m_1} : p_{ij}(m_1) > 0
	\]
	Niech \( n_0 = m_0 + m_1 \)
	\[
		\forall_{n \geq n_0} p_{ij}(n) \geq p_{ij}(m_1)p_{jj}(n-m_1) > 0
	\]
\end{proof}
%</probabil-2025-11-19-lancuchy-nieprzywiedlne>

%<*probabil-2025-11-19-stany-definicje2>
\begin{definition}
	Definiujemy \textbf{piewszy czas pojawienia się w j} jako:
	\[
		T_j = \min\pars{n \in \natural \mid X_n = j}
	\]
	\[
		T_j^+ = \min\pars{n \in \natural_1 \mid X_n = j}
	\]
	W drugim przypadku pomijamy stan początkowy \( n = 0 \)
\end{definition}

\begin{definition}
	Definiujemy \textbf{prawdopodobieństwo pierwszego spotkania w zadanym momencie} \(f_{ij}(n)\)
	jako
	\[
		f_{ij}(n) = P(X_n = j \land X_{n-1} \neq j \dots X_{1} \neq j \mid X_0 = i) = P(T_j^+ = n \mid X_0 = i)
	\]
\end{definition}

\begin{definition}
	Definiujemy \textbf{prawdopodobieństwo pierwszego spotkania} \(f_{ij}\)
	jako
	\[
		f_{ij} = \sum_{n=1}^{\infty} f_{ij}(n) = P(T_j^+ = n \mid X_0 = i)
	\]
\end{definition}
%</probabil-2025-11-19-stany-definicje2>

%<*probabil-2025-11-19-stany-powracajace>
\begin{definition}
	Stan \(i\) jest \textbf{powracający (rekurencyjny)} jeśli \( f_{i, i} = 1 \),
	a \textbf{chwilowy} jeśli \( f_{i, i} < 1 \). \\
	Mówimy, że łańcuch jest rekurencyjny jeśli każdy jego stan jest rekurencyjny.
\end{definition}

\begin{definition}
	Definiujemy \textbf{czas pierwszego spotkania} 
	\[
		T_{i, j} = \min \set{n \in \natural_1 \mid X_0 = i \land X_n = j}
	\]
	dodatkowo
	\[
		\ev{T_{i, j}} = \ev{T_j^+ \mid X_0 = i} = \sum_{n = 1}^\infty n \prob(T_j^+ = n \mid X_0 = i)
	\]
\end{definition}

\begin{definition}
	Stan powracający \(i\) jest \textbf{dodatni} jeśli \(\ev{T_{i, i}} < \infty\),
	w przeciwnym wypadku jest \textbf{zerowy}.
\end{definition}

\begin{example}
	Niech zbiór stanów \(S = \natural_1\) oraz niech
	\[
		\prob(X_{j + 1} = i + 1 \mid X_j = i) = \frac{i}{i+1}
	\]
	\[
		\prob(X_{j + 1} = 1 \mid X_j = i) = \frac{1}{i+1}
	\]
	\begin{center}
		\tikz {
			\tikzstyle{fixed_size_circle}=[circle, draw, minimum size=1.0cm]
			\node [fixed_size_circle,draw] (1) at (0, 0) {1};
			\node at (3, 0) {\(\dots\dots\dots\dots\dots\dots\dots\)};
			\node [fixed_size_circle,draw] (i) at (6, 0) {i};
			\node [fixed_size_circle,draw] (i+1) at (8, 0) {i+1};
			
			\draw [->, thick] (i) edge [bend left=45] 
				node [midway, above] {\(\frac{1}{i+1}\)}
				(1);
			\draw [->, thick] (i) edge [bend left=45] 
				node [midway, above] {\(\frac{i}{i+1}\)}
				(i+1);
		}
	\end{center}

	\[
		\prob(T_1^+ > t \mid X_0 = 1) = \frac{1}{2} \cdot \frac{2}{3} \dots \frac{t}{t+1} = \frac{1}{t+1}
	\]
	\[
		f_{1, 1} = \prob(T_1^+ < \infty \mid X_0 = 1) = 1 - \lim_{t \to \infty} \prob(T_1^+ > t \mid X_0 = 1) = 1 - \lim_{t \to \infty} \frac{1}{t+1} = 1
	\]
	\[
		\ev{T_{1, 1}} = \sum_{t = 1}^\infty t \prob(T_i^+ = t \mid X_0 = i) = \sum_{t = 1}^\infty t \pars{\frac{1}{2} \dots \frac{t-1}{t} \frac{1}{t+1}} = \sum_{t = 1}^\infty \frac{1}{t+1} \to \infty
	\]
	Z \(f_{1, 1} = 1\) stan 1 jest powracający, a z \(\ev{T_{1, 1}} \to \infty\) jest zerowy.
\end{example}

\begin{theorem}
	W skończonym, nieprzywiedlnym łańcuchu Markowa zachodzi
	\[
		\forall_{x, y} \quad \ev{T_{x, y}} < \infty
	\]
\end{theorem}
\begin{proof}
	Nieprzywiedlność oraz skończoność dają nam
	\[
		\exists_{r > 0, \varepsilon > 0} \quad \forall_{x, y \in S} \quad \exists_{j \in [r]} \quad p_{x, y}(j) > \varepsilon
	\]
	Mimo tego, że linia ta może początkowo być trudna do przetworzenia, jest całkiem prosta. Nieprzywiedlność mówi nam że dla każdego \((x, y)\), \(y\) jest osiągalne z \(x\), a więc \(\exists_n \quad p_{x, y}(n) > 0\). Nasze \(r\) to po prostu maksimum po tych \(n\) dla wszystkich par \((x, y)\), a \(\varepsilon\) to minimum z wartości \(p_{x, y}(n)\).
	
	Następnie chcemy pokazać, że
	\[
		\prob(T_y^+ > kr \mid X_0 = x) \leq \prob(T_y^+ > (k - 1)r \mid X_0 = x)(1 - \varepsilon)
	\]
	Dlaczego tak jest? Otóż wiemy, że dla każdej możliwej wartości \(z = X_{(k-1)r}\) zachodzi \(\exists_{j \in [r]} \quad p_{z, y}((k - 1)r + j) > \varepsilon\), a więc z prawdopodobieństwem przynajmniej \(\varepsilon\) odwiedzimy \(y\) w następnych \(r\) krokach. W takim razie, jeśli \(T_y^+ > (k-1)r\), to \(\prob(T_y^+ \leq kr) \geq \varepsilon\), a więc prawdopodobieństwo tego, że nie dojdziemy do \(y\) jest ograniczone od góry przez \(1 - \varepsilon\), co daje nam naszą nierówność.
	
	Następnie, poprzez prostą indukcję można pokazać, że
	\[
		\prob(T_y^+ > kr \mid X_0 = x) \leq (1 - \varepsilon)^k
	\]
	Teraz, przechodząc do finalnego dowodu
	\begin{align*}
		\ev{T_{x, y}} &= \ev{T_y^+ \mid X_0 = x}\\
		&=\footnotemark \sum_{t = 0}^\infty \prob(T_y^+ > t \mid X_0 = x)\\
		&\leq \sum_{k = 0}^\infty r \prob(T_y^+ > kr \mid X_0 = x)\\
		&\leq r \sum_{k = 0}^\infty (1 - \varepsilon)^k \\
		&< \infty
    \end{align*}
	\footnotetext{Wynika to z \ref{expected-value-of-natural-random-variable}}
\end{proof}
%</probabil-2025-11-19-stany-powracajace>

\begin{definition}
	Stan jest \textbf{ergodyczny} jeśli jest nieokresowy i pozytywnie rekurencyjny.
	Łańcuch jest ergodyczny jeśli każdy jego stan jest ergodyczny.
\end{definition}

\begin{lemma}
	W skończonym procesie Markowa:
	\begin{enumerate}
		\item istnieje co najmniej jeden stan rekurencyjny
		\item każdy stan rekurencyjny jest pozytywnie rekurencyjny
	\end{enumerate}

\end{lemma}
\begin{proof} \( \) \\
	\begin{enumerate}
		\item Załóżmy nie wprost, że wszystkie stany są chwilowe.

		      Niech \( Y_1, \dots, Y_n \) będą zmiennymi losowymi liczącymi liczbę powrotów do każdego ze stanów.

		      Zmienne te mają rozkład geometryczny -- jeśli wychodzimy z \(i\)-tego stanu to z prawdopodobieństwem \(p = \sum_{i = 1}^\infty r_{i, i}^t \) wracamy kiedyś do \( i \) (co liczmy jako porażkę) a z prawdopodobieństwem \( 1 - p \) nigdy już nie wracamy do tego stanu (co liczymy jako sukces).

		      Ponieważ z definicji \( p < 1 \) to \( 1 - p > 0 \)
		      zatem
		      \[
			      \forall_i : \expected{Y_i} \in \real
		      \]

		      Z drugiej jednak strony łańcuch trwa nieskończenie długo, czyli
		      \[
			      \infty = \expected{\sum_i Y_i} = \sum_i \expected{Y_i}
		      \]
		      co nam daje sprzeczność.

		\item

	\end{enumerate}
\end{proof}

Z lematu tego wysuwamy poniższy wniosek:
\begin{lemma}
	Skończony, nieredukowalny, nieokresowy łańcuch Markowa jest ergodyczny
\end{lemma}

\begin{lemma}
	Jeśli stan \(x\) jest rekurencyjny to
	wszystkie stany w tej samej klasie skomunikowania również są rekurencyjne.
\end{lemma}
\begin{proof}
	Wybierzmy dowolny stan \( y \) w tej samej klasie skomunikowania co \( x \).
	Pokażemy, że jest on rekurencyjny.

	Rozważmy zachowanie naszego łańcucha na stanach \( x \) oraz \( y \).
	Możliwe jest kilka zdarzeń:
	\begin{enumerate}
		\item Wychodząc ze stanu \( x \) wracamy do \( x \) zanim napotkamy \( y \) -- z prawdopodobieństwem \( p \)

		\item Wychodząc ze stanu \( x \) zanim wrócimy do \( x \) to napotykamy \( y \) \\
		      Ponieważ \( x \) jest rekurencyjny to to zdarzenie ma szansę \( 1 - p \)

		\item Wychodząc ze stanu \( y \) wracamy do \( y \) zanim napotkamy \( x \) -- z prawdopodobieństwem \( q \)
		\item Wychodząc ze stanu \( y \) napotkamy \( x \) zanim wrócimy do \( y \) -- z prawdopodobieństwem \( r \)

		\item Wychodząc ze stanu \( y \) nigdy nie wracamy ani do \( x \) ani do \( y \) -- z prawdopodobieństwem \( s \)
	\end{enumerate}
	Oczywiście \( q + r + s = 1 \) bo zdarzenia te wyczerpują wszystkie możliwe zachowania łańcucha.
	Ponadto ze skomunikowania mamy \( 1 - p > 0, r > 0 \)
	Poniżej przedstawiamy graficzną reprezentację opisanych zdarzeń.

	\begin{figure}[H]
		\centering
		\includegraphics{img/markov-chains/recurrent-communicated-a-priori.png}
		\caption{Ilustracja przejść między możliwymi sytuacjami}
	\end{figure}

	Jak się dobrze przyjrzymy to dojdziemy do wniosku, że \( s = 0 \). Dlaczego ?
	Bo inaczej z prawdopodobieństwem co najmniej \( (1-p) \cdot s \) wychodząc z \( x \)
	nigdy już do niego nie wrócimy, co jest sprzeczne z założeniem że jest on rekurencyjny.

	W takim razie \(s = 0\), a co za tym idzie \(r = 1 - q\), możemy zatem uprościć nieco nasz rysunek:

	\begin{figure}[H]
		\centering
		\includegraphics{img/markov-chains/recurrent-communicated-a-posteriori.png}
		\caption{Ilustracja przejść między możliwymi sytuacjami po uproszczeniu}
	\end{figure}

	Aby pokazać, że \( y \) jest rekurencyjny pokażemy, że prawdopodobieństwo na to, że wychodząc z \(y \) od pewnego momentu nigdy już nie wrócimy do \( y \) jest zerowe.
	Do \( y \) nigdy nie wracamy, jeśli po skończonej liczbie kroków trafiamy do \( x \) a następnie
	nigdy już nie wracamy do \( y \).

	Innymi słowy przechodzimy nieskończenie wiele razy po pętli \( x \rightarrow x \) za każdym razem z prawdopodobieństem \( p \), a szansa na takie zdarzenie wynosi \( \lim_{n \rightarrow \infty} p^n = 0 \)

\end{proof}
