%<*probabil-2025-12-19-centralne-twierdzenie-graniczne-1>
\subsection{Podstawowa wersja}
Intuicyjnie: Centralne Twierdzenie Graniczne mówi, że jak mamy niezależne zmienne losowe o takim samym rozkładzie, to dla liczby prób zbiegającej do nieskończoności rozkład średniej arytmetycznej tych wylosowanych wartości będzie zbiegać do rozkładu normalnego.
Twierdzenie to uzasadnia występowanie w naturze rozkładu normalnego.
%</probabil-2025-12-19-centralne-twierdzenie-graniczne-1>
\begin{definition}
	Ciąg dystrybuant \( F_1, F_2, ... \) zbiega w dystrybuancie do dystrybuanty \( F\), co oznaczamy jako \(F_n \to F \), jeśli dla każdego \(a \in \mathbb{R} \) w którym \( F \) jest ciągła zachodzi:
	\[
		\lim_{n \to \infty} F_n(a) = F(a)
	\]
\end{definition}

%<*probabil-2025-12-19-centralne-twierdzenie-graniczne-2>
\begin{theorem}[Centralne Twierdzenie Graniczne]
	Niech \(\set{X_i}_{i \in \natural}\) będą niezależnymi zmiennymi losowymi o takim samym rozkładzie, wartości oczekiwanej \( \mu\) i wariancji \( \sigma^2\). Niech \( \widetilde{X_n} = \frac{1}{n}\sum_{i=1}^n X_i \). Wówczas dla dowolnych \(a, b\)
	\[
		\lim_{n \to \infty} \prob \pars{a \leq \frac{ \widetilde{X_n} - \ev{\widetilde{X_n}}}{\sqrt{\variance{\widetilde{X_n}}}} \leq b} = \Phi(b) - \Phi(a)
	\]
\end{theorem}
\begin{proof}
	Pierwsze, przekształćmy sobie trochę nasz cel
	\[
		\ev{\widetilde{X_n}} = \mu
	\]
	\[
		\variance{\widetilde{X_n}} = \variance{\frac{1}{n}\sum_{i=1}^n X_i} = \frac{1}{n^2} \variance{\sum_{i=1}^n X_i} = \frac{1}{n^2} \sum_{i=1}^n \variance{X_i} = \frac{1}{n^2} n \sigma^2 = \frac{\sigma^2}{n}
	\]
	A więc
	\[
		\lim_{n \to \infty} \prob \pars{a \leq \frac{ \widetilde{X_n} - \ev{\widetilde{X_n}}}{\sqrt{\variance{\widetilde{X_n}}}} \leq b} = \lim_{n \to \infty} \prob \pars{a \leq \frac{ \widetilde{X_n} - \mu}{\sigma} \cdot \sqrt{n} \leq b}
	\]
	
	Dalej, aby dowieść CTG, będziemy musieli przytoczyć \textit{pomocne twierdzonko}, którego (mamy nadzieję) nikt nie będzie musiał dowodzić:

	\begin{theorem}[Lévy-Cramér] 
		Niech \(\set{Y_i}_{i \in \natural}\) będzie sekwencją zmiennych losowych, gdzie \(Y_i\) ma dystrybuantę \(F_i\) i funkcję tworzącą momenty \( M_i\). Niech \(Y\) będzie zmienną losową o dystrybuancie \(F\) i funkcji tworzącej momenty \(M\). Jeżeli dla każdego \(t\) zachodzi:
		\[
			\lim_{n \to \infty}M_n(t) = M(t)
		\]

		to dla każdego \(t\) takiego, że \(F\) jest ciągła w \(t\) zachodzi
		\[
			\lim_{n \to \infty} F_n(t) = F(t)
		\]
	\end{theorem}
	\begin{proof}
		Mitzenmacher przytacza to twierdzenie bez dowodu; na wykładzie go również nie było, a więc i my udowodnimy je poprzez założenie go jako aksjomat (haha).
	\end{proof}

	Przystępujemy teraz do dowodzenia CTG.

	Definiujemy \( Z_i = \frac{X_i - \mu}{\sigma} \).
	Wówczas \( Z_i\) są niezależnymi zmiennymi losowymi oraz

	\[
		\expected{Z_i} = \expected{\frac{X_i - \mu}{ \sigma}} = \frac{1}{\sigma} \cdot \pars{\expected{X_i} - \expected{\mu}} = \frac{1}{\sigma} \cdot \pars{\mu - \mu} = 0
	\]

	\[
		\variance{Z_i} = \variance{\frac{X_i - \mu}{\sigma}} = \frac{1}{\sigma^2} \cdot \pars{\variance{X_i - \mu}} = \frac{1}{\sigma^2} \cdot \pars{\variance{X_i} - \variance{\mu}} = \frac{1}{\sigma^2} \cdot \pars{\sigma^2 - 0} = 1
	\]
	
	\[
		\variance{Z_i} = \ev{Z_i^2} - \ev{Z_i}^2 \implies \ev{Z_i^2} = \variance{Z_i} + \ev{Z_i}^2 = 1 + 0^2 = 1
	\]

	Ponadto mamy, że:
	\[
		\frac{\widetilde{X_n} - \mu}{\sigma} \cdot \sqrt{n} 
		= \frac{\sum_{i=1}^n \frac{X_i}{n} - \mu}{\sigma} \cdot \sqrt{n} 
		= \frac{\sum_{i=1}^n \frac{X_i - \mu}{n}}{\sigma} \cdot \sqrt{n} 
		= \frac{\sqrt{n}}{n}\sum_{i=1}^{n}\frac{X_i-\mu}{\sigma} 
		= \frac{\sum_{i=1}^nZ_i}{\sqrt{n}}
	\]
	Żeby zastosować teraz przywołane przez nas twierdzenie Levy'ego i tego drugiego musimy pokazać, że funkcja tworząca momenty zmiennych losowych postaci
	\[
		Y_n = \frac{\sum_{i=1}^nZ_i}{\sqrt{n}}
	\]
	zbiega do funkcji tworzącej momenty zmiennej losowej o standardowym rozkładzie normalnym. Po zastosowaniu tego twierdzenia dostalibyśmy już tezę Centralnego Twierdzenia Granicznego.

	W takim razie, chcemy pokazać
	\[
		\lim_{n \to \infty} M_{Y_n}(t) = \lim_{n \to \infty}\expected{e^{t\frac{\sum_{i=1}^nZ_i}{\sqrt{n}}}} = e^{\frac{t^2}{2}}
	\]
	Niech \( M_{Z_i}(t) = \expected{e^{tZ_i}} \) będzie funkcją tworzącą momenty zmiennej \(Z_i\).  Zauważamy, że wówczas funkcja tworząca momenty zmiennej losowej \( \frac{Z_i}{\sqrt{n}}\) wynosi
	\[
		M_{\frac{Z_i}{\sqrt{n}}} (t) = \expected{e^{t \cdot \frac{Z_i}{\sqrt{n}}}} = M_{Z_i} \pars{\frac{t}{\sqrt{n}}}
	\]
	Ponieważ \( Z_i\) są niezależne i mają ten sam rozkład mamy
	\[
		M_{Y_n}(t) = M_{\sum_{i=1}^{n} \frac{Z_i}{\sqrt{n}}} (t) = \pars{M_{\frac{Z_i}{\sqrt{n}}}(t)}^n = \pars{M_{Z_i}\pars{\frac{t}{\sqrt{n}}}}^n
	\]

	Teraz wykonujemy \textit{magiczne założenie}. Zdefiniujmy sobie, \textbf{for no reason at all}, funkcję \(L\), taką że

	\[
		L(t) = \ln M_{Z_i}(t)
	\]

	Dodatkowo, \textit{również bez jakiejkolwiek przyczyny}, policzmy sobie pierwszą i drugą pochodną \(L(0)\).

	Zacznijmy od trywialnych obserwacji:
	\[
		M_{Z_i}(0) = 1 \implies L(0) = 0
	\]
	\[
		L'(0) = \pars{\ln M_{Z_i}(0)}' = \frac{1}{M_{Z_i}(0)} \cdot M'_{Z_i}(0) = \frac{M_{Z_i}'(0)}{M_{Z_i}(0)} = \frac{\expected{Z_i}}{1} = \expected{Z_i} = 0
	\]
	\[
		L''(0) = \frac{M_{Z_i}(0)M_{Z_i}''(0) - (M_{Z_i}'(0))^2}{(M_{Z_i}(0))^2} = \frac{M_{Z_i}''(0) - 0}{1} = \expected{Z_i^2} = 1
	\]

	Przypomnijmy, że chcieliśmy pokazać, że


	\[
		\lim_{n\to\infty}M_{Y_n}\pars{t} = \lim_{n \to \infty } \pars{M_{Z_i}\pars{\frac{t}{\sqrt{n}}}}^n = e^{\frac{t^2}{2}}
	\]
	
	po zlogarytmowaniu stronami

	\[
		\lim_{n \to \infty} nL\pars{\frac{t}{\sqrt{n}}} = \frac{t^2}{2}
	\]

	Pytanie teraz co musimy zrobić by wykazać, że ta granica tyle wynosi.

	Jak wszyscy wiemy, kiedy nie wiadomo jak policzyć granicę, to liczymy ją L’Hôpitalem. Zapiszmy więc sobie ten limit tak, byśmy mogli użyć tego twierdzenia (czyli żeby pojawił się symbol nieoznaczony \( \frac{0}{0} \)).
	\[
		\lim_{n \to \infty}\frac{L\pars{\frac{t}{\sqrt{n}}}}{n^{-1}}
	\]

	No i lecimy z pochodnymi!

	\begin{align*}
		\lim_{n \to \infty}\frac{L \pars{\frac{t}{\sqrt{n}}}}{n^{-1}} &= \brackets{\frac{0}{0}}\\
		&= \lim_{n \to \infty}\frac{-\frac{1}{2}L'\pars{\frac{t}{\sqrt{n}}}tn^{-\frac{3}{2}}}{-n^{-2}}               \\
		& = \lim_{n \to \infty}\frac{L'\pars{\frac{t}{\sqrt{n}}}t}{2n^{-\frac{1}{2}}}                       \\
		&= \brackets{\frac{0}{0}}\\
		& = \lim_{n \to \infty}\frac{-\frac{1}{2}L''\pars{\frac{t}{\sqrt{n}}}t^2 n^{-\frac{3}{2}}}{-\frac{1}{2}2n^{-\frac{3}{2}}} \\
		& = \lim_{n \to \infty} \frac{t^2 \cdot L''\pars{\frac{t}{\sqrt{n}}}}{2}                            \\
		& = \lim_{n \to \infty} \frac{t^2 \cdot 1 }{2}                                                      \\
		& = \frac{t^2}{2}
	\end{align*}

	I w sumie to mieliśmy dowieść. Ale fajnie.
\end{proof}

\subsection{Warianty}
Istnieją różne warianty CTG, które mają swoje zastosowania w różnych sytuacjach. Poniżej podajemy wypowiedzi dwóch takich wariantów.

W pierwszym wariancie usuwamy warunek na to, że wszystkie zmienne \(X_i\) muszą mieć taki sam rozkład, ale musimy za to dodać dwa dodatkowe warunki.
\begin{theorem}
	Niech \(\set{X_i}_{i \in \natural}\) będzie ciągiem niezależnych zmiennych losowych spełniających \(\mathbb{E}\left[ X_i \right] = \mu_i\) i \(\variance{X_i} = \sigma_i^2\). Niech zachodzi
	\begin{enumerate}
		\item \(\exists_{M>0} \ \forall_{i \in \natural} \ P\left( \left|X_i\right|<M \right) = 1 \)
		\item \( \lim_{n \to \infty} \sum_{i=1}^{n} \sigma_i^2 = +\infty\).
	\end{enumerate}
	Wówczas dla dowolnych \(a, b\) zachodzi
	\[ 
		\lim_{n \to \infty} P\left( a \le \frac{ \sum_{i=1}^{n} \left( X_i - \mu_i \right) }{\sqrt{ \sum_{i=1}^{n} \sigma_i^2} } \le  b  \right) = \Phi\pars{b} - \Phi\pars{a}
	\]
\end{theorem}

Za to w drugim wariancie mając dodakową informację o trzecim momencie, możemy wyznaczyć prędkość zbiegania do rozkładu normalnego
\begin{theorem}[Berry-Ess\'een]
	Istnieje taka stała \(C\), że dla każdego ciągu niezależnych zmiennych losowych \(\set{X_i}_{i \in \natural}\) o tym samym rozkładzie ze skończoną wartością oczekiwaną \(\mu\) i wariancją \(\sigma^2\) oraz dla \(\rho = \mathbb{E}\left[ \left|X_i-\mu\right|^3 \right] < \infty \) i \(\widetilde{X_n} = \frac{1}{n} \sum_{i=1}^{n} X_i\) zachodzi
	
	\[ 
		\left|P\left( \frac{\widetilde{X_n}-\mu}{\frac{\sigma}{\sqrt{n} }} \le a \right) - \Phi\left( a  \right) \right| \le C\cdot \frac{\rho}{\sigma^3 \sqrt{n} }
	\]
\end{theorem}
%</probabil-2025-12-19-centralne-twierdzenie-graniczne-2>