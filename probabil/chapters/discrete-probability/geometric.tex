%<*probabil-egzamin-rozklad-geometryczny-1>
%<*probabil-2025-10-10-rozklad-geometryczny-1>
\begin{definition}
	Mówimy, że zmienna losowa \( X \) ma \textbf{rozkład geometryczny} z parametrem \( p \in (0, 1) \) jeśli
	dla \( n > 0 \)
	\[
		\prob(X = n) = (1 - p)^{n-1} \cdot p
	\]
\end{definition}

\begin{theorem}[Lemat 2.8 P\&C]
	\label{geometric-is-memoryless}
	Rozkład geometryczny jest \textbf{bez pamięci} tzn. jeśli \( X \) ma rozkład geometryczny z parametrem \( p \) to
	\[
		\forall_{n, k} : \prob(X = n + k \mid X > k) = \prob(X = n)
	\]
\end{theorem}
\begin{proof}
	Zauważmy najpierw, że dla dowolnego \( 0 < p < 1 \) mamy
	\[
		\sum_{i=k}^\infty (1-p)^i = (1-p)^k \cdot \frac{1}{1 - (1-p)} = \frac{(1-p)^k}{p}
	\]

	W takim razie
	\begin{align*}
		\prob(X = n + k \mid X > k)
		 & = \frac{\prob(X = n + k \land X > k)}{\prob(X > k)}                             \\
		 & = \frac{\prob(X = n + k)}{\prob(X > k)}                                         \\
		 & = \frac{(1 - p)^{n + k - 1} \cdot p}{\sum_{i=k}^\infty (1-p)^i \cdot p} \\
		 & = \frac{(1-p)^{n + k - 1}}{\sum_{i=k}^\infty (1-p)^i}                   \\
		 & = (1-p)^{n + k - 1} \cdot \frac{p}{(1-p)^k}                             \\
		 & = (1-p)^{n-1} \cdot p                                                   \\
		 & = \prob(X = n)
	\end{align*}
\end{proof}
%</probabil-2025-10-10-rozklad-geometryczny-1>
%</probabil-egzamin-rozklad-geometryczny-1>

%<*probabil-2025-10-10-rozklad-geometryczny-3>
\begin{theorem}
	\label{geometric-expected-value}
	Niech \( X \) ma rozkład geometryczny z parametrem \( p \). Wtedy
	\[
		\expected{X} = \frac{1}{p}
	\]
\end{theorem}
\begin{proof}
	Skorzystamy z twierdzenia \ref{expected-value-of-natural-random-variable}
	\begin{align*}
		\expected{X}
		 & = \sum_{n=1}^\infty \prob(X \geq n)                           \\
		 & = \sum_{n=1}^\infty \sum_{i=n}^\infty (1-p)^{i-1} \cdot p \\
		 & = \sum_{n=1}^\infty (1-p)^n                               \\
		 & = \frac{1}{1 - (1-p)}                                     \\
		 & = \frac{1}{p}
	\end{align*}
	
	Alternatywna metoda:

	\(Y = \begin{cases}
		1 & \text{sukces w pierwszym rzucie} \\
		0 & \text{wpp.}
	\end{cases}\)
	\begin{align*}
		\ev{X} &= \ev{X|Y=0}\prob(Y=0) + \ev{X|Y=1}\prob(Y=1) \\
		&= (1+\ev{X})(1-p) + 1 \cdot p \\
		&= 1 + \ev{X} - p \ev{X}
	\end{align*}
	\[
		p \ev{X} = 1 \implies \ev{X} = \frac{1}{p}
	\]
\end{proof}
%</probabil-2025-10-10-rozklad-geometryczny-3>

%<*probabil-2025-10-24-wariancja-rozkladu-geometrycznego>
\begin{theorem}
	\label{variance-of-geometric}
	Niech \( X \) ma rozkład geometryczny z parametrem \( p \). Wtedy
	\[
		\variance{X} = \frac{1 - p}{p^2}
	\]
\end{theorem}
\begin{proof}
	Pokazaliśmy w \ref{geometric-expected-value}, że \( \expected{X} = \frac{1}{p} \). Pozostaje nam zatem policzyć \( \expected{X^2} \)

	Zaczniemy od pokazania pomocniczych równości.

	Wiemy, że dla \( 0 < x < 1 \)
	\[
		\frac{1}{1-x} = \sum_{i=0}^\infty x^i
	\]
	Różniczkujemy obustronnie
	\[
		\frac{1}{(1-x)^2} = \sum_{i=0}^\infty i x^{i-1} = \sum_{i=0}^\infty (i+1)x^i
	\]
	I jeszcze raz
	\[
		\frac{2}{(1-x)^3} = \sum_{i=0}^\infty i (i+1) x^{i-1}
		= \sum_{i=0}^\infty (i+1)(i+2)x^i
	\]

	W takim razie
	\begin{align*}
		\sum_{i=1}^\infty i^2 x^i & = \sum_{i=0}^\infty i^2 x^i                                                \\
		                          & = \sum x^i \cdot \pars{i^2 + 3i + 2 - 3(i + 1) + 1}                        \\
		                          & = \sum (i+1)(i+2)x^i - 3\sum_{i=1}^\infty (i+1)x^i + \sum_{i=1}^\infty x_i \\
		                          & = \frac{2}{(1-x)^3} - 3\cdot\frac{1}{(1-x)^2} + \frac{1}{1-x}              \\
		                          & = \frac{x^2 + x}{(1-x)^3}
	\end{align*}

	Teraz możemy przejść do głównych obliczeń:
	\begin{align*}
		\expected{X^2}
		 & = \sum_{i=1}^\infty i^2 \cdot (1-p)^{i-1} p                 \\
		 & = \frac{p}{1 - p} \cdot \sum_{i=1}^\infty i^2 \cdot (1-p)^i \\
		 & = \frac{p}{1-p}\cdot\frac{(1-p)^2 + (1-p)}{p^3}             \\
		 & = \frac{(1-p) + 1}{p^2} = \frac{2 - p}{p^2}
	\end{align*}

	Dowód kończymy obliczając wariancję
	\[
		\variance{X} = \expected{X^2} - \expected{X}^2 = \frac{2-p}{p^2} - \frac{1}{p^2} = \frac{1-p}{p^2}
	\]
\end{proof}
Alternatywny dowód
\begin{proof} Niech \(Y\) ma rozkład geometryczny z parametrem \(p\)\\
	Niech \(X = \begin{cases}
		1 & \text{w pierwszym rzucie orzeł} \\
		0 & \text{w pierwszym rzucie reszka}
	\end{cases}\)\\
	Z \ref{ev-equal-to-sum-of-conditional-ev} mamy:
	\begin{align*}
		\ev{Y^2}
			& = \prob(X = 0) \ev{Y^2 \mid X = 0} + \prob(X = 1) \ev{Y^2 \mid X = 1}\\
			& = (1-p)\ev{Y^2 \mid X = 0} + p\ev{Y^2 \mid X = 1}\\
	\end{align*}
	Wiemy, że
	\begin{itemize}
		\item Dla \(X = 1\), \(Y = 1\), a więc \(E(Y^2 \mid X = 1) = 1\)
		\item Dla \(X = 0\), \(Y > 1\). Niech \(Z\) to liczba pozostałych rzutów do otrzymania pierwszego orła
	\end{itemize}
	W takim razie
	\[
		\ev{Y^2} = (1-p)\ev{(Z + 1)^2} + p = (1-p)\ev{Z^2} + 2(1-p)\ev{Z} + 1
	\]
	Wiemy z \ref{geometric-is-memoryless}, że rozkład geometryczny jest bez pamięci, a więc \(Z\) też ma rozkład geometryczny z parametrem \(p\), a więc \(\ev{Z} = \frac{1}{p}, \ev{Z^2} = \ev{Y^2}\), co znaczy, że
	\[
		\ev{Y^2} = (1-p)\ev{Y^2} + 2(1-p)\frac{1}{p} + 1 \implies p\ev{Y^2} = \frac{2-p}{p} \implies \ev{Y^2} = \frac{2-p}{p^2}
	\]
\end{proof}
%</probabil-2025-10-24-wariancja-rozkladu-geometrycznego>

%<*probabil-egzamin-rozklad-geometryczny-2>
%<*probabil-2025-10-24-funkcja-tworzaca-dla-rozkladu-geometrycznego>
\begin{theorem}
	Niech \( X \) ma rozkład geometryczny z parametrem \( p \). Wtedy tworząca tej zmiennej wynosi
	\[
		M_X(t) = \frac{pe^t}{1 - (1-p)e^t}
	\]
	dla \( t < -\ln (1-p) \).
\end{theorem}

\begin{proof}
	\begin{align*}
		M_X(t)
		 & = \expected{e^{tX}}                                                         \\
		 & = \sum_{i=1}^\infty (1-p)^{i-1}pe^{ik}                                      \\
		 & = \frac{p}{1 - p} \cdot \sum_{i=1}^\infty \pars{(1-p)e^t}^i                 \\
		 & = \frac{p}{1-p} \cdot \pars{\pars{\sum_{i=0}^\infty \pars{(1-p)e^t}^i} - 1} \\
		 & = \frac{p}{1-p} \cdot \pars{\frac{1}{1 - (1-p)e^t} - 1}                     \\
		 & = \frac{p}{1-p} \cdot \frac{(1-p)e^t}{1 - (1-p)e^t}                         \\
		 & = \frac{pe^t}{1 - (1-p)e^t}
	\end{align*}
	Skorzystaliśmy tutaj z faktu, że szereg \[ \sum_{i=1}^\infty \pars{(1-p)e^t}^i \]
	jest zbieżny. Dzieje się tak gdy
	\[
		(1-p)e^t < 1
	\]
	\[
		e^t < \frac{1}{1-p}
	\]
	\[
		t < -\ln (1-p)
	\]
\end{proof}

\begin{corollary}
	\label{variance-of-geometric-by-mgf}
	%</probabil-egzamin-rozklad-geometryczny-2>
    Wcześniej obliczyliśmy już \( \expected{X} \) oraz \( \expected{X^2} \). Możemy to też zrobić z funkcji tworzącej momentów.
	
	%<*probabil-egzamin-rozklad-geometryczny-3>
    Wiemy, że \( M_X^{(n)}(0) = \expected{X^n} \). Obliczamy więc \( M_X^{(1)}(t) \) oraz \( M_X^{(2)}(t) \). Otrzymujemy:

    \[
        M_X^{(1)}(t) = p(1-(1-p)e^t)^{-2}
    \]

    \[
        M_X^{(2)}(t) = 2p(1-p)(1-(1-p)e^t)^{-3}e^{2t} + p(1-(1-p)e^t)^{-2}e^t
    \]

    Po podstawieniu \( t = 0 \) otrzymujemy znane już wartości:

    \[
        M_X^{(1)}(0) = \expected{X} = \frac{1}{p}
    \]

    \[
        M_X^{(2)}(0) = \expected{X^2} = \frac{2-p}{p^2} \implies \variance{X} = \frac{1-p}{p^2}
    \]
\end{corollary}
%</probabil-egzamin-rozklad-geometryczny-3>
%</probabil-2025-10-24-funkcja-tworzaca-dla-rozkladu-geometrycznego>
